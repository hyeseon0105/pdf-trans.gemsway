{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Fine-tuning ì™„ì „ ê°€ì´ë“œ",
    "### Cadwell Korea ì˜ë£Œê¸°ê¸° ë¸Œë¡œì…” ë²ˆì—­ ëª¨ë¸ í•™ìŠµ",
    "",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒ ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤:",
    "1. OpenAI API ì„¤ì •",
    "2. JSONL ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ",
    "3. Fine-tuning ì‘ì—… ì‹œì‘",
    "4. í•™ìŠµ ìƒíƒœ ëª¨ë‹ˆí„°ë§",
    "5. í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸",
    "6. Backendì—ì„œ ì‚¬ìš©í•˜ëŠ” ì½”ë“œ ì˜ˆì‹œ",
    "",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ OpenAI ì„¤ì¹˜ ë° API í‚¤ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜",
    "!pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì…ë ¥",
    "# OpenAI í”Œë«í¼ì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
    "# https://platform.openai.com/api-keys",
    "",
    "import os",
    "from openai import OpenAI",
    "",
    "# ì—¬ê¸°ì— API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
    "API_KEY = \"\"  # ì˜ˆ: \"sk-proj-...\"",
    "",
    "# ë˜ëŠ” Colab Secrets ì‚¬ìš© (ê¶Œì¥)",
    "# from google.colab import userdata",
    "# API_KEY = userdata.get('OPENAI_API_KEY')",
    "",
    "if not API_KEY:",
    "    raise ValueError(\"âŒ API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”!\")",
    "",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”",
    "client = OpenAI(api_key=API_KEY)",
    "",
    "print(\"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ JSONL í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ",
    "",
    "ì¢Œì¸¡ íŒŒì¼ íƒ­ì—ì„œ `training_data.jsonl` íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸",
    "import os",
    "",
    "TRAINING_FILE = \"training_data.jsonl\"",
    "",
    "if not os.path.exists(TRAINING_FILE):",
    "    print(\"âŒ training_data.jsonl íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”!\")",
    "    print(\"   ì¢Œì¸¡ íŒŒì¼ ì•„ì´ì½˜ > ì—…ë¡œë“œ ë²„íŠ¼ í´ë¦­\")",
    "else:",
    "    # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°",
    "    import json",
    "    ",
    "    with open(TRAINING_FILE, 'r', encoding='utf-8') as f:",
    "        lines = f.readlines()",
    "    ",
    "    print(f\"âœ… íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")",
    "    print(f\"   ì´ í•™ìŠµ ì˜ˆì œ ìˆ˜: {len(lines)}ê°œ\")",
    "    print(f\"\\nì²« ë²ˆì§¸ ì˜ˆì œ:\")",
    "    ",
    "    first_example = json.loads(lines[0])",
    "    for msg in first_example['messages']:",
    "        print(f\"\\n[{msg['role'].upper()}]\")",
    "        print(msg['content'][:100] + ('...' if len(msg['content']) > 100 else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ OpenAI Files APIì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Files APIì— í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ",
    "print(\"ğŸ“¤ OpenAI Files APIì— ì—…ë¡œë“œ ì¤‘...\")",
    "",
    "with open(TRAINING_FILE, \"rb\") as f:",
    "    training_file = client.files.create(",
    "        file=f,",
    "        purpose=\"fine-tune\"",
    "    )",
    "",
    "print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ!\")",
    "print(f\"   íŒŒì¼ ID: {training_file.id}\")",
    "print(f\"   íŒŒì¼ëª…: {training_file.filename}\")",
    "print(f\"   ìƒíƒœ: {training_file.status}\")",
    "print(f\"   í¬ê¸°: {training_file.bytes} bytes\")",
    "",
    "# íŒŒì¼ ID ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)",
    "FILE_ID = training_file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Fine-tuning ì‘ì—… ì‹œì‘",
    "",
    "ê¸°ë³¸ ëª¨ë¸: `gpt-4o-mini-2024-07-18`  ",
    "í•™ìŠµ ì‹œê°„: ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ìˆ˜ ë¶„ ~ ìˆ˜ì‹­ ë¶„ ì†Œìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning ì‘ì—… ìƒì„±",
    "print(\"ğŸš€ Fine-tuning ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")",
    "print(\"   ê¸°ë³¸ ëª¨ë¸: gpt-4o-mini-2024-07-18\")",
    "print(\"   ëª©ì : Cadwell Korea ì˜ë£Œê¸°ê¸° ë¸Œë¡œì…” ë²ˆì—­\\n\")",
    "",
    "fine_tuning_job = client.fine_tuning.jobs.create(",
    "    training_file=FILE_ID,",
    "    model=\"gpt-4o-mini-2024-07-18\",",
    "    hyperparameters={",
    "        \"n_epochs\": 3,  # ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 3-4, ë°ì´í„°ê°€ ë§ìœ¼ë©´ 1-2ë¡œ ì¤„ì—¬ë„ ë¨)",
    "    },",
    "    suffix=\"cadwell-medical-ko\"  # ëª¨ë¸ëª…ì— ì¶”ê°€ë  ì ‘ë¯¸ì‚¬",
    ")",
    "",
    "print(f\"âœ… Fine-tuning ì‘ì—…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")",
    "print(f\"   ì‘ì—… ID: {fine_tuning_job.id}\")",
    "print(f\"   ìƒíƒœ: {fine_tuning_job.status}\")",
    "print(f\"   ìƒì„± ì‹œê°„: {fine_tuning_job.created_at}\")",
    "",
    "# ì‘ì—… ID ì €ì¥",
    "JOB_ID = fine_tuning_job.id",
    "",
    "print(f\"\\nâ³ í•™ìŠµì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ë‹¤ìŒ ì…€ì—ì„œ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ í•™ìŠµ ìƒíƒœ ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ í™•ì¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)",
    "job_status = client.fine_tuning.jobs.retrieve(JOB_ID)",
    "",
    "print(f\"ğŸ“Š Fine-tuning ì‘ì—… ìƒíƒœ\")",
    "print(f\"   ì‘ì—… ID: {job_status.id}\")",
    "print(f\"   ìƒíƒœ: {job_status.status}\")",
    "print(f\"   ê¸°ë³¸ ëª¨ë¸: {job_status.model}\")",
    "print(f\"   ìƒì„± ì‹œê°„: {job_status.created_at}\")",
    "",
    "if job_status.fine_tuned_model:",
    "    print(f\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")",
    "    print(f\"   Fine-tuned ëª¨ë¸ ID: {job_status.fine_tuned_model}\")",
    "else:",
    "    print(f\"\\nâ³ í•™ìŠµ ì§„í–‰ ì¤‘... ì ì‹œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")",
    "    ",
    "    if job_status.status == \"failed\":",
    "        print(f\"\\nâŒ í•™ìŠµ ì‹¤íŒ¨!\")",
    "        if job_status.error:",
    "            print(f\"   ì˜¤ë¥˜: {job_status.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ê³„ì† ì‹¤í–‰)",
    "import time",
    "from datetime import datetime",
    "",
    "print(\"ğŸ”„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (Ctrl+Cë¡œ ì¤‘ë‹¨)\\n\")",
    "",
    "try:",
    "    while True:",
    "        job = client.fine_tuning.jobs.retrieve(JOB_ID)",
    "        ",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")",
    "        print(f\"[{current_time}] ìƒíƒœ: {job.status}\", end=\"\")",
    "        ",
    "        if job.status == \"succeeded\":",
    "            print(f\"\\n\\nâœ… í•™ìŠµ ì™„ë£Œ!\")",
    "            print(f\"   Fine-tuned ëª¨ë¸ ID: {job.fine_tuned_model}\")",
    "            FINE_TUNED_MODEL = job.fine_tuned_model",
    "            break",
    "        elif job.status == \"failed\":",
    "            print(f\"\\n\\nâŒ í•™ìŠµ ì‹¤íŒ¨!\")",
    "            if job.error:",
    "                print(f\"   ì˜¤ë¥˜: {job.error}\")",
    "            break",
    "        else:",
    "            print(\" (ì§„í–‰ ì¤‘...)\")",
    "        ",
    "        time.sleep(30)  # 30ì´ˆë§ˆë‹¤ í™•ì¸",
    "        ",
    "except KeyboardInterrupt:",
    "    print(\"\\n\\nâ¸ï¸  ëª¨ë‹ˆí„°ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "    print(\"   í•™ìŠµì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤. ìœ„ ì…€ë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ í•™ìŠµ ì´ë²¤íŠ¸ ë¡œê·¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning ì´ë²¤íŠ¸ ë¡œê·¸ ì¡°íšŒ",
    "from datetime import datetime",
    "",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=JOB_ID, limit=20)",
    "",
    "print(\"ğŸ“œ ìµœê·¼ 20ê°œ ì´ë²¤íŠ¸ ë¡œê·¸:\\n\")",
    "",
    "for event in events.data:",
    "    timestamp = datetime.fromtimestamp(event.created_at).strftime(\"%Y-%m-%d %H:%M:%S\")",
    "    print(f\"[{timestamp}] {event.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ í•™ìŠµëœ ëª¨ë¸ ID í™•ì¸ ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… Fine-tuned ëª¨ë¸ ID í™•ì¸",
    "final_job = client.fine_tuning.jobs.retrieve(JOB_ID)",
    "",
    "if final_job.fine_tuned_model:",
    "    FINE_TUNED_MODEL = final_job.fine_tuned_model",
    "    ",
    "    print(\"âœ… Fine-tuned ëª¨ë¸ ì •ë³´\")",
    "    print(\"=\" * 60)",
    "    print(f\"ëª¨ë¸ ID: {FINE_TUNED_MODEL}\")",
    "    print(\"=\" * 60)",
    "    print(\"\\nì´ ëª¨ë¸ IDë¥¼ ë³µì‚¬í•˜ì—¬ Backend ì½”ë“œì— ì‚¬ìš©í•˜ì„¸ìš”!\")",
    "    print(\"\\nì˜ˆì‹œ:\")",
    "    print(f'OPENAI_MODEL = \"{FINE_TUNED_MODEL}\"')",
    "    ",
    "    # íŒŒì¼ë¡œ ì €ì¥",
    "    with open(\"fine_tuned_model_id.txt\", \"w\") as f:",
    "        f.write(FINE_TUNED_MODEL)",
    "    print(\"\\nğŸ’¾ ëª¨ë¸ IDê°€ 'fine_tuned_model_id.txt'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "    ",
    "else:",
    "    print(\"âŒ Fine-tuned ëª¨ë¸ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")",
    "    print(f\"   í˜„ì¬ ìƒíƒœ: {final_job.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë²ˆì—­ (í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned ëª¨ë¸ë¡œ ë²ˆì—­ í…ŒìŠ¤íŠ¸",
    "def test_translation(english_text: str, model_id: str) -> str:",
    "    \"\"\"",
    "    Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­",
    "    \"\"\"",
    "    response = client.chat.completions.create(",
    "        model=model_id,",
    "        messages=[",
    "            {",
    "                \"role\": \"system\",",
    "                \"content\": \"Cadwell Korea ì˜ë£Œê¸°ê¸° ë¸Œë¡œì…” ì „ë¬¸ ë²ˆì—­ê°€\"",
    "            },",
    "            {",
    "                \"role\": \"user\",",
    "                \"content\": english_text",
    "            }",
    "        ],",
    "        temperature=0.3,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©",
    "    )",
    "    ",
    "    return response.choices[0].message.content",
    "",
    "",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤",
    "test_sentences = [",
    "    \"Cadwell's EMG solutions are designed for comprehensive neuromuscular diagnostics.\",",
    "    \"Our devices provide accurate and reliable measurements for clinical assessments.\",",
    "    \"The system integrates seamlessly with existing hospital infrastructure.\",",
    "    \"Advanced signal processing ensures optimal data quality.\"",
    "]",
    "",
    "print(\"ğŸ§ª Fine-tuned ëª¨ë¸ í…ŒìŠ¤íŠ¸\\n\")",
    "print(\"=\" * 60)",
    "",
    "if 'FINE_TUNED_MODEL' not in locals():",
    "    print(\"âŒ FINE_TUNED_MODELì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")",
    "    print(\"   ìœ„ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ IDë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.\")",
    "else:",
    "    for i, sentence in enumerate(test_sentences, 1):",
    "        print(f\"\\n[í…ŒìŠ¤íŠ¸ {i}]\")",
    "        print(f\"ì›ë¬¸: {sentence}\")",
    "        ",
    "        translation = test_translation(sentence, FINE_TUNED_MODEL)",
    "        print(f\"ë²ˆì—­: {translation}\")",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ ê¸°ë³¸ ëª¨ë¸ê³¼ ë¹„êµ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned ëª¨ë¸ vs ê¸°ë³¸ ëª¨ë¸ ë¹„êµ",
    "test_text = \"The integrated workflow provides efficient patient data management and reporting.\"",
    "",
    "print(\"ğŸ“Š ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸\")",
    "print(\"=\" * 60)",
    "print(f\"\\nì›ë¬¸:\\n{test_text}\\n\")",
    "",
    "# ê¸°ë³¸ ëª¨ë¸ (gpt-4o-mini)",
    "print(\"[ê¸°ë³¸ ëª¨ë¸: gpt-4o-mini]\")",
    "base_translation = test_translation(test_text, \"gpt-4o-mini\")",
    "print(f\"{base_translation}\\n\")",
    "",
    "# Fine-tuned ëª¨ë¸",
    "if 'FINE_TUNED_MODEL' in locals():",
    "    print(f\"[Fine-tuned ëª¨ë¸: {FINE_TUNED_MODEL}]\")",
    "    finetuned_translation = test_translation(test_text, FINE_TUNED_MODEL)",
    "    print(f\"{finetuned_translation}\\n\")",
    "    ",
    "    print(\"-\" * 60)",
    "    print(\"\\nğŸ’¡ Fine-tuned ëª¨ë¸ì€ í•™ìŠµ ë°ì´í„°ì˜ ìŠ¤íƒ€ì¼ê³¼ ìš©ì–´ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.\")",
    "else:",
    "    print(\"\\nâš ï¸  Fine-tuned ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Backendì—ì„œ ì‚¬ìš©í•˜ëŠ” ì½”ë“œ (Python FastAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backend ì½”ë“œ ì˜ˆì‹œ ì¶œë ¥",
    "if 'FINE_TUNED_MODEL' in locals():",
    "    backend_code = f'''",
    "# backend/app/services/translate_service.py",
    "",
    "from openai import OpenAI",
    "import os",
    "",
    "# Fine-tuned ëª¨ë¸ ID (í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬ ê¶Œì¥)",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")",
    "FINE_TUNED_MODEL = \"{FINE_TUNED_MODEL}\"",
    "",
    "client = OpenAI(api_key=OPENAI_API_KEY)",
    "",
    "",
    "def translate_with_finetuned_model(english_text: str) -> str:",
    "    \"\"\"",
    "    Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­",
    "    ",
    "    Args:",
    "        english_text: ë²ˆì—­í•  ì˜ì–´ í…ìŠ¤íŠ¸",
    "        ",
    "    Returns:",
    "        ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸",
    "    \"\"\"",
    "    try:",
    "        response = client.chat.completions.create(",
    "            model=FINE_TUNED_MODEL,",
    "            messages=[",
    "                {{",
    "                    \"role\": \"system\",",
    "                    \"content\": \"Cadwell Korea ì˜ë£Œê¸°ê¸° ë¸Œë¡œì…” ì „ë¬¸ ë²ˆì—­ê°€\"",
    "                }},",
    "                {{",
    "                    \"role\": \"user\",",
    "                    \"content\": english_text",
    "                }}",
    "            ],",
    "            temperature=0.3,",
    "            max_tokens=2000,",
    "        )",
    "        ",
    "        return response.choices[0].message.content",
    "        ",
    "    except Exception as e:",
    "        print(f\"ë²ˆì—­ ì˜¤ë¥˜: {{e}}\")",
    "        raise",
    "",
    "",
    "# ì‚¬ìš© ì˜ˆì‹œ",
    "if __name__ == \"__main__\":",
    "    test_text = \"The EMG system provides comprehensive diagnostic capabilities.\"",
    "    result = translate_with_finetuned_model(test_text)",
    "    print(f\"ì›ë¬¸: {{test_text}}\")",
    "    print(f\"ë²ˆì—­: {{result}}\")",
    "'''",
    "    ",
    "    print(\"ğŸ“ Backend í†µí•© ì½”ë“œ\")",
    "    print(\"=\" * 60)",
    "    print(backend_code)",
    "    print(\"=\" * 60)",
    "    ",
    "    # íŒŒì¼ë¡œ ì €ì¥",
    "    with open(\"backend_integration_code.py\", \"w\", encoding=\"utf-8\") as f:",
    "        f.write(backend_code)",
    "    ",
    "    print(\"\\nğŸ’¾ 'backend_integration_code.py' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "else:",
    "    print(\"âš ï¸  ë¨¼ì € Fine-tuned ëª¨ë¸ IDë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env íŒŒì¼ ì˜ˆì‹œ ìƒì„±",
    "if 'FINE_TUNED_MODEL' in locals():",
    "    env_content = f'''# OpenAI API ì„¤ì •",
    "OPENAI_API_KEY=sk-proj-your-api-key-here",
    "OPENAI_MODEL={FINE_TUNED_MODEL}",
    "",
    "# ë²ˆì—­ ì œê³µì ì„¤ì •",
    "TRANSLATION_PROVIDER=openai",
    "",
    "# ê¸°íƒ€ ì„¤ì •",
    "FRONTEND_ORIGIN=http://localhost:5173",
    "'''",
    "    ",
    "    print(\"ğŸ“„ .env íŒŒì¼ ì˜ˆì‹œ\")",
    "    print(\"=\" * 60)",
    "    print(env_content)",
    "    print(\"=\" * 60)",
    "    ",
    "    with open(\"example.env\", \"w\", encoding=\"utf-8\") as f:",
    "        f.write(env_content)",
    "    ",
    "    print(\"\\nğŸ’¾ 'example.env' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "    print(\"   ì´ íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— '.env'ë¡œ ë³µì‚¬í•˜ê³  API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ ëª¨ë“  Fine-tuning ì‘ì—… ëª©ë¡ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  Fine-tuning ì‘ì—… ì¡°íšŒ",
    "from datetime import datetime",
    "",
    "jobs = client.fine_tuning.jobs.list(limit=10)",
    "",
    "print(\"ğŸ“‹ ìµœê·¼ Fine-tuning ì‘ì—… ëª©ë¡ (ìµœëŒ€ 10ê°œ)\\n\")",
    "print(\"=\" * 80)",
    "",
    "for job in jobs.data:",
    "    created = datetime.fromtimestamp(job.created_at).strftime(\"%Y-%m-%d %H:%M:%S\")",
    "    ",
    "    print(f\"ì‘ì—… ID: {job.id}\")",
    "    print(f\"ìƒíƒœ: {job.status}\")",
    "    print(f\"ê¸°ë³¸ ëª¨ë¸: {job.model}\")",
    "    print(f\"ìƒì„± ì‹œê°„: {created}\")",
    "    ",
    "    if job.fine_tuned_model:",
    "        print(f\"Fine-tuned ëª¨ë¸: {job.fine_tuned_model}\")",
    "    ",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£3ï¸âƒ£ Fine-tuned ëª¨ë¸ ì‚­ì œ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ ì£¼ì˜: ì´ ì…€ì€ Fine-tuned ëª¨ë¸ì„ ì‚­ì œí•©ë‹ˆë‹¤!",
    "# ì‹¤í–‰í•˜ê¸° ì „ì— model_to_delete ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.",
    "",
    "# ì‚­ì œí•  ëª¨ë¸ ID ì…ë ¥",
    "model_to_delete = \"\"  # ì˜ˆ: \"ft:gpt-4o-mini-2024-07-18:...\"",
    "",
    "if model_to_delete:",
    "    confirm = input(f\"ì •ë§ë¡œ '{model_to_delete}' ëª¨ë¸ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): \")",
    "    ",
    "    if confirm.lower() == \"yes\":",
    "        try:",
    "            client.models.delete(model_to_delete)",
    "            print(f\"âœ… ëª¨ë¸ '{model_to_delete}'ì´(ê°€) ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "        except Exception as e:",
    "            print(f\"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}\")",
    "    else:",
    "        print(\"ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")",
    "else:",
    "    print(\"âš ï¸  model_to_delete ë³€ìˆ˜ì— ì‚­ì œí•  ëª¨ë¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤",
    "",
    "- [OpenAI Fine-tuning ê³µì‹ ë¬¸ì„œ](https://platform.openai.com/docs/guides/fine-tuning)",
    "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/fine-tuning)",
    "- [Fine-tuning ê°€ê²© ì •ë³´](https://openai.com/pricing)",
    "",
    "---",
    "",
    "## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸",
    "",
    "- [ ] OpenAI API í‚¤ ì„¤ì •",
    "- [ ] training_data.jsonl íŒŒì¼ ì—…ë¡œë“œ",
    "- [ ] Files APIì— ì—…ë¡œë“œ",
    "- [ ] Fine-tuning ì‘ì—… ì‹œì‘",
    "- [ ] í•™ìŠµ ì™„ë£Œ í™•ì¸",
    "- [ ] Fine-tuned ëª¨ë¸ ID ì €ì¥",
    "- [ ] í…ŒìŠ¤íŠ¸ ë²ˆì—­ ì‹¤í–‰",
    "- [ ] Backend ì½”ë“œì— ëª¨ë¸ ID ì ìš©",
    "- [ ] .env íŒŒì¼ì— API í‚¤ì™€ ëª¨ë¸ ID ì„¤ì •",
    "",
    "---",
    "",
    "**ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! Fine-tuningì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.**",
    "",
    "ì´ì œ í•™ìŠµëœ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}